# -*- coding: utf-8 -*-
"""cycle_hire_analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jT7Le4kz3MhuWWb0mZcuE78aG7qylB0g
"""

# Load the raw TfL cycle-hire dataset into Colab
from google.colab import files
import pandas as pd
import io

uploaded = files.upload()

filename = list(uploaded.keys())[0]
df = pd.read_csv(io.StringIO(uploaded[filename].decode('utf-8')))

# Preview the first few rows of the raw dataset
df.head()

## Create time variables for peak vs off-peak analysis
# Convert Start date to datetime
df['Start date'] = pd.to_datetime(df['Start date'])

# Create time-based features
df['hour'] = df['Start date'].dt.hour
df['weekday'] = df['Start date'].dt.weekday  # 0 = Monday
df['day_type'] = df['weekday'].apply(lambda x: 'Weekday' if x < 5 else 'Weekend')

# Inspect derived time variables to confirm correct transformation
df[['Start date', 'hour', 'day_type']].head()

## Define weekday peak periods (H1)

# Mark journeys that start during weekday commuter hours (07–09 and 16–18)
df['peak'] = (
    (df['day_type'] == 'Weekday') &
    (
        ((df['hour'] >= 7) & (df['hour'] < 9)) |
        ((df['hour'] >= 16) & (df['hour'] < 18))
    )
)
# Confirm logic has been applied correctly
df[['hour', 'day_type', 'peak']].head(10)

# Check how many journeys fall into peak and off-peak periods
df['peak'].value_counts()

## Prepare trip duration for analysis (H2)

# Convert trip duration from milliseconds to minutes
df['duration_minutes'] = df['Total duration (ms)'] / 60000

# Look at summary statistics to spot very short or very long trips
df['duration_minutes'].describe()

# Check how many trips last longer than 120 minutes to remove outliers
df['duration_minutes'].gt(120).sum()

## Remove trips with unrealistic durations

# Keep trips between 1 and 120 minutes
clean_df = df[
    (df['duration_minutes'] >= 1) &
    (df['duration_minutes'] <= 120)
]

# Check how many rows remain after cleaning
print("Original rows:", len(df))
print("Cleaned rows:", len(clean_df))
print("Rows removed:", len(df) - len(clean_df))

## Make an Exeter-like subset (remove very central London start stations)

# Remove journeys that start in very central London areas (not really comparable to Exeter)
central_keywords = [
    'Westminster', 'City of London', 'Soho', 'Covent Garden', 'Holborn',
    'Waterloo', 'Strand', 'Piccadilly', 'Oxford Circus', 'Trafalgar'
]

exeter_like_df = clean_df[
    ~clean_df['Start station'].str.contains('|'.join(central_keywords), case=False, na=False)
]

# Quick check that we didn’t remove too much
print("Before filter:", len(clean_df))
print("After filter:", len(exeter_like_df))
print("Removed:", len(clean_df) - len(exeter_like_df))

# Descriptive checks (Task 1 metrics): demand level, trip duration, and bike-type mix

# Metric A: Peak vs off-peak demand (mean hourly journeys)
hourly_demand = (
    exeter_like_df
    .groupby(['hour', 'peak'])
    .size()
    .reset_index(name='journeys')
)
print("Mean hourly journeys by peak flag:")
print(hourly_demand.groupby('peak')['journeys'].mean())

# Metric B: Trip duration (minutes) by bike type
print("\nTrip duration (minutes) summary by bike type:")
print(exeter_like_df.groupby('Bike model')['duration_minutes'].describe()[['count','mean','std','min','25%','50%','75%','max']])

# Metric C: Bike-type share (% of journeys)
print("\nBike-type share (% of journeys):")
print(exeter_like_df['Bike model'].value_counts(normalize=True).mul(100).round(2))

## Analyse H1: Demand during peak vs off-peak periods

# Aggregate journeys to hourly demand
hourly_demand = (
    exeter_like_df
    .groupby(['hour', 'peak'])
    .size()
    .reset_index(name='journeys')
)
# Check the hourly demand table looks right
hourly_demand.head()

# See peak and off-peak demand side by side
hourly_demand.pivot(index='hour', columns='peak', values='journeys')

# Compare average hourly demand between peak and off-peak
hourly_demand.groupby('peak')['journeys'].mean()

## Analyse H2: Trip duration by bike type

# Check average trip duration for classic bikes vs e-bikes
exeter_like_df.groupby('Bike model')['duration_minutes'].describe()

## Compare the number of journeys by bike type

bike_type_counts = exeter_like_df['Bike model'].value_counts(normalize=True) * 100
bike_type_counts

## Compare bike type usage during peak vs off-peak periods (descriptive context)

peak_bike_share = (
    exeter_like_df
    .groupby(['peak', 'Bike model'])
    .size()
    .groupby(level=0)
    .apply(lambda x: x / x.sum() * 100)
)

peak_bike_share

# Save the cleaned, Exeter-like dataset for reproducibility
exeter_like_df.to_csv(
    'exeter_like_cycle_hire_cleaned.csv',
    index=False
)

## Visual 1: Average demand during peak vs off-peak periods

import matplotlib.pyplot as plt

# Aggregate journeys to hourly demand using the Exeter-like dataset
hourly_demand_exeter = (
    exeter_like_df
    .groupby(['hour', 'peak'])
    .size()
    .reset_index(name='journeys')
)

# Calculate average journeys in peak vs off-peak periods
peak_demand = (
    hourly_demand_exeter
    .groupby('peak')['journeys']
    .mean()
)

# Create polished bar chart
plt.figure()
peak_demand.plot(kind='bar', width=0.6)
plt.title('Average Cycle-Hire Demand: Peak vs Off-Peak Periods')
plt.xlabel('')
plt.ylabel('Average Number of Journeys')
plt.xticks([0, 1], ['Off-peak', 'Peak'], rotation=0)
plt.tight_layout()
plt.savefig('fig1_peak_vs_offpeak.png', bbox_inches='tight')
plt.show()

## Visual 2: Distribution of trip duration by bike type

import matplotlib.pyplot as plt

plt.figure()
exeter_like_df.boxplot(
    column='duration_minutes',
    by='Bike model',
    showfliers=False
)

plt.title('Trip Duration by Bike Type')
plt.suptitle('')
plt.xlabel('Bike Type')
plt.ylabel('Trip Duration (minutes)')

# Rename x-axis labels for readability
plt.xticks(
    [1, 2],
    ['Classic bike', 'E-bike']
)

plt.tight_layout()
plt.savefig('fig2_duration_by_biketype.png', bbox_inches='tight')
plt.show()

## Prepare data for predictive modelling

model_df = (
    exeter_like_df
    .groupby(['hour', 'peak'])
    .size()
    .reset_index(name='journeys')
)

model_df.head()

# Convert peak to numeric (0 = off-peak, 1 = peak)
model_df['peak_numeric'] = model_df['peak'].astype(int)

model_df.head()

## Simple predictive model to estimate hourly demand during peak vs off-peak periods
from sklearn.linear_model import LinearRegression

X = model_df[['peak_numeric']]
y = model_df['journeys']

model = LinearRegression()
model.fit(X, y)

# Extract model parameters
intercept = model.intercept_
coefficient = model.coef_[0]

print("Intercept (off-peak demand):", intercept)
print("Coefficient (additional peak demand):", coefficient)

import os

os.listdir()

from google.colab import files
files.download('exeter_like_cycle_hire_cleaned.csv')